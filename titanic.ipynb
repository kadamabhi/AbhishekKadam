{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train=pd.read_csv(r\"C:\\Users\\abhis\\Desktop\\Python\\Data\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test=pd.read_csv(r\"C:\\Users\\abhis\\Desktop\\Python\\Data\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test['Survived']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'Survived'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "t_train['data']='train'\n",
    "t_test['data']='test'\n",
    "t_all=pd.concat([t_train,t_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0   NaN        S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                           Allen, Mr. William Henry      0            5   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived            Ticket   data  \n",
       "0       3    male      1       0.0         A/5 21171  train  \n",
       "1       1  female      1       1.0          PC 17599  train  \n",
       "2       3  female      0       1.0  STON/O2. 3101282  train  \n",
       "3       1  female      1       1.0            113803  train  \n",
       "4       3    male      0       0.0            373450  train  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age            float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "Fare           float64\n",
       "Name            object\n",
       "Parch            int64\n",
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Sex             object\n",
       "SibSp            int64\n",
       "Survived       float64\n",
       "Ticket          object\n",
       "data            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_all.drop(['Name','Ticket','Cabin',],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Embarked     Fare  Parch  PassengerId  Pclass     Sex  SibSp  \\\n",
       "0  22.0        S   7.2500      0            1       3    male      1   \n",
       "1  38.0        C  71.2833      0            2       1  female      1   \n",
       "2  26.0        S   7.9250      0            3       3  female      0   \n",
       "3  35.0        S  53.1000      0            4       1  female      1   \n",
       "4  35.0        S   8.0500      0            5       3    male      0   \n",
       "\n",
       "   Survived   data  \n",
       "0       0.0  train  \n",
       "1       1.0  train  \n",
       "2       1.0  train  \n",
       "3       1.0  train  \n",
       "4       0.0  train  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=t_all.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Embarked', 'Sex', 'data'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=cat_cols[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Embarked', 'Sex'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked\n",
      "Sex\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    freqs=t_all[col].value_counts()\n",
    "    k=freqs.index[freqs>20][:-1]\n",
    "    for cat in k:\n",
    "        name=col+'_'+cat\n",
    "        t_all[name]=(t_all[col]==cat).astype(int)\n",
    "    del t_all[col]\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age            float64\n",
       "Fare           float64\n",
       "Parch            int64\n",
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "SibSp            int64\n",
       "Survived       float64\n",
       "data            object\n",
       "Embarked_S       int32\n",
       "Embarked_C       int32\n",
       "Sex_male         int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all.head()\n",
    "t_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age            263\n",
       "Fare             1\n",
       "Parch            0\n",
       "PassengerId      0\n",
       "Pclass           0\n",
       "SibSp            0\n",
       "Survived       418\n",
       "data             0\n",
       "Embarked_S       0\n",
       "Embarked_C       0\n",
       "Sex_male         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in t_all.columns:\n",
    "    if (col not in ['Survived','data'])& (t_all[col].isnull().sum()>0):\n",
    "        t_all.loc[t_all[col].isnull(),col]=t_all.loc[t_all['data']=='train',col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age              0\n",
       "Fare             0\n",
       "Parch            0\n",
       "PassengerId      0\n",
       "Pclass           0\n",
       "SibSp            0\n",
       "Survived       418\n",
       "data             0\n",
       "Embarked_S       0\n",
       "Embarked_C       0\n",
       "Sex_male         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "t_train=t_all[t_all['data']=='train']\n",
    "del t_train['data']\n",
    "t_test=t_all[t_all['data']=='test']\n",
    "t_test.drop(['Survived','data'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'class_weight':['balanced',None],\n",
    "        'penalty':['l1','l2'],\n",
    "        'C':np.linspace(0.01,1000,10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV(model,param_grid=params,cv=5,scoring=\"roc_auc\",verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=t_train.drop('Survived',axis=1)\n",
    "y_train=t_train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=t_train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] C=0.01, class_weight=balanced, penalty=l1 .......................\n",
      "[CV]  C=0.01, class_weight=balanced, penalty=l1, score=0.5641633728590251, total=   0.0s\n",
      "[CV] C=0.01, class_weight=balanced, penalty=l1 .......................\n",
      "[CV]  C=0.01, class_weight=balanced, penalty=l1, score=0.7337285902503294, total=   0.0s\n",
      "[CV] C=0.01, class_weight=balanced, penalty=l1 .......................\n",
      "[CV]  C=0.01, class_weight=balanced, penalty=l1, score=0.6890374331550801, total=   0.0s\n",
      "[CV] C=0.01, class_weight=balanced, penalty=l1 .......................\n",
      "[CV]  C=0.01, class_weight=balanced, penalty=l1, score=0.7474598930481283, total=   0.0s\n",
      "[CV] C=0.01, class_weight=balanced, penalty=l1 .......................\n",
      "[CV]  C=0.01, class_weight=balanced, penalty=l1, score=0.7481111710739342, total=   0.0s\n",
      "[CV] C=0.01, class_weight=balanced, penalty=l2 .......................\n",
      "[CV]  C=0.01, class_weight=balanced, penalty=l2, score=0.7409749670619236, total=   0.0s\n",
      "[CV] C=0.01, class_weight=balanced, penalty=l2 .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.01, class_weight=balanced, penalty=l2, score=0.8208168642951251, total=   0.0s\n",
      "[CV] C=0.01, class_weight=balanced, penalty=l2 .......................\n",
      "[CV]  C=0.01, class_weight=balanced, penalty=l2, score=0.8118983957219251, total=   0.0s\n",
      "[CV] C=0.01, class_weight=balanced, penalty=l2 .......................\n",
      "[CV]  C=0.01, class_weight=balanced, penalty=l2, score=0.8212566844919788, total=   0.0s\n",
      "[CV] C=0.01, class_weight=balanced, penalty=l2 .......................\n",
      "[CV]  C=0.01, class_weight=balanced, penalty=l2, score=0.8679168915272532, total=   0.0s\n",
      "[CV] C=0.01, class_weight=None, penalty=l1 ...........................\n",
      "[CV]  C=0.01, class_weight=None, penalty=l1, score=0.5666666666666667, total=   0.0s\n",
      "[CV] C=0.01, class_weight=None, penalty=l1 ...........................\n",
      "[CV]  C=0.01, class_weight=None, penalty=l1, score=0.7266139657444006, total=   0.0s\n",
      "[CV] C=0.01, class_weight=None, penalty=l1 ...........................\n",
      "[CV]  C=0.01, class_weight=None, penalty=l1, score=0.664572192513369, total=   0.0s\n",
      "[CV] C=0.01, class_weight=None, penalty=l1 ...........................\n",
      "[CV]  C=0.01, class_weight=None, penalty=l1, score=0.7136363636363637, total=   0.0s\n",
      "[CV] C=0.01, class_weight=None, penalty=l1 ...........................\n",
      "[CV]  C=0.01, class_weight=None, penalty=l1, score=0.725580140313006, total=   0.0s\n",
      "[CV] C=0.01, class_weight=None, penalty=l2 ...........................\n",
      "[CV]  C=0.01, class_weight=None, penalty=l2, score=0.7513833992094862, total=   0.0s\n",
      "[CV] C=0.01, class_weight=None, penalty=l2 ...........................\n",
      "[CV]  C=0.01, class_weight=None, penalty=l2, score=0.8229249011857708, total=   0.0s\n",
      "[CV] C=0.01, class_weight=None, penalty=l2 ...........................\n",
      "[CV]  C=0.01, class_weight=None, penalty=l2, score=0.8156417112299466, total=   0.0s\n",
      "[CV] C=0.01, class_weight=None, penalty=l2 ...........................\n",
      "[CV]  C=0.01, class_weight=None, penalty=l2, score=0.8271390374331551, total=   0.0s\n",
      "[CV] C=0.01, class_weight=None, penalty=l2 ...........................\n",
      "[CV]  C=0.01, class_weight=None, penalty=l2, score=0.8753372908796545, total=   0.0s\n",
      "[CV] C=111.12, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=111.12, class_weight=balanced, penalty=l1, score=0.8458498023715415, total=   0.0s\n",
      "[CV] C=111.12, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=111.12, class_weight=balanced, penalty=l1, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=111.12, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=111.12, class_weight=balanced, penalty=l1, score=0.852139037433155, total=   0.0s\n",
      "[CV] C=111.12, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=111.12, class_weight=balanced, penalty=l1, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=111.12, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=111.12, class_weight=balanced, penalty=l1, score=0.8722342147868322, total=   0.0s\n",
      "[CV] C=111.12, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=111.12, class_weight=balanced, penalty=l2, score=0.8463768115942029, total=   0.0s\n",
      "[CV] C=111.12, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=111.12, class_weight=balanced, penalty=l2, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=111.12, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=111.12, class_weight=balanced, penalty=l2, score=0.8522727272727273, total=   0.0s\n",
      "[CV] C=111.12, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=111.12, class_weight=balanced, penalty=l2, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=111.12, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=111.12, class_weight=balanced, penalty=l2, score=0.8719643820831084, total=   0.0s\n",
      "[CV] C=111.12, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=111.12, class_weight=None, penalty=l1, score=0.8482213438735178, total=   0.0s\n",
      "[CV] C=111.12, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=111.12, class_weight=None, penalty=l1, score=0.8334650856389987, total=   0.0s\n",
      "[CV] C=111.12, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=111.12, class_weight=None, penalty=l1, score=0.852673796791444, total=   0.0s\n",
      "[CV] C=111.12, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=111.12, class_weight=None, penalty=l1, score=0.8378342245989305, total=   0.0s\n",
      "[CV] C=111.12, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=111.12, class_weight=None, penalty=l1, score=0.871424716675661, total=   0.0s\n",
      "[CV] C=111.12, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=111.12, class_weight=None, penalty=l2, score=0.8480895915678525, total=   0.0s\n",
      "[CV] C=111.12, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=111.12, class_weight=None, penalty=l2, score=0.8349143610013176, total=   0.0s\n",
      "[CV] C=111.12, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=111.12, class_weight=None, penalty=l2, score=0.8522727272727273, total=   0.0s\n",
      "[CV] C=111.12, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=111.12, class_weight=None, penalty=l2, score=0.8378342245989305, total=   0.0s\n",
      "[CV] C=111.12, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=111.12, class_weight=None, penalty=l2, score=0.8718294657312466, total=   0.0s\n",
      "[CV] C=222.23, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=222.23, class_weight=balanced, penalty=l1, score=0.8461133069828721, total=   0.0s\n",
      "[CV] C=222.23, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=222.23, class_weight=balanced, penalty=l1, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=222.23, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=222.23, class_weight=balanced, penalty=l1, score=0.852139037433155, total=   0.0s\n",
      "[CV] C=222.23, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=222.23, class_weight=balanced, penalty=l1, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=222.23, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=222.23, class_weight=balanced, penalty=l1, score=0.8723691311386941, total=   0.0s\n",
      "[CV] C=222.23, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=222.23, class_weight=balanced, penalty=l2, score=0.8463768115942029, total=   0.0s\n",
      "[CV] C=222.23, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=222.23, class_weight=balanced, penalty=l2, score=0.8326745718050066, total=   0.0s\n",
      "[CV] C=222.23, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=222.23, class_weight=balanced, penalty=l2, score=0.8522727272727273, total=   0.0s\n",
      "[CV] C=222.23, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=222.23, class_weight=balanced, penalty=l2, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=222.23, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=222.23, class_weight=balanced, penalty=l2, score=0.8719643820831084, total=   0.0s\n",
      "[CV] C=222.23, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=222.23, class_weight=None, penalty=l1, score=0.8482213438735178, total=   0.0s\n",
      "[CV] C=222.23, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=222.23, class_weight=None, penalty=l1, score=0.8333333333333333, total=   0.0s\n",
      "[CV] C=222.23, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=222.23, class_weight=None, penalty=l1, score=0.8521390374331551, total=   0.0s\n",
      "[CV] C=222.23, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=222.23, class_weight=None, penalty=l1, score=0.8377005347593582, total=   0.0s\n",
      "[CV] C=222.23, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=222.23, class_weight=None, penalty=l1, score=0.8716945493793847, total=   0.0s\n",
      "[CV] C=222.23, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=222.23, class_weight=None, penalty=l2, score=0.847957839262187, total=   0.0s\n",
      "[CV] C=222.23, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=222.23, class_weight=None, penalty=l2, score=0.8334650856389987, total=   0.0s\n",
      "[CV] C=222.23, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=222.23, class_weight=None, penalty=l2, score=0.8524064171122995, total=   0.0s\n",
      "[CV] C=222.23, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=222.23, class_weight=None, penalty=l2, score=0.8379679144385026, total=   0.0s\n",
      "[CV] C=222.23, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=222.23, class_weight=None, penalty=l2, score=0.8714247166756611, total=   0.0s\n",
      "[CV] C=333.34, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=333.34, class_weight=balanced, penalty=l1, score=0.8461133069828722, total=   0.0s\n",
      "[CV] C=333.34, class_weight=balanced, penalty=l1 .....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=333.34, class_weight=balanced, penalty=l1, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=333.34, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=333.34, class_weight=balanced, penalty=l1, score=0.852139037433155, total=   0.0s\n",
      "[CV] C=333.34, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=333.34, class_weight=balanced, penalty=l1, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=333.34, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=333.34, class_weight=balanced, penalty=l1, score=0.8723691311386941, total=   0.0s\n",
      "[CV] C=333.34, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=333.34, class_weight=balanced, penalty=l2, score=0.8462450592885375, total=   0.0s\n",
      "[CV] C=333.34, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=333.34, class_weight=balanced, penalty=l2, score=0.8326745718050066, total=   0.0s\n",
      "[CV] C=333.34, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=333.34, class_weight=balanced, penalty=l2, score=0.852139037433155, total=   0.0s\n",
      "[CV] C=333.34, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=333.34, class_weight=balanced, penalty=l2, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=333.34, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=333.34, class_weight=balanced, penalty=l2, score=0.8722342147868322, total=   0.0s\n",
      "[CV] C=333.34, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=333.34, class_weight=None, penalty=l1, score=0.8484848484848484, total=   0.0s\n",
      "[CV] C=333.34, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=333.34, class_weight=None, penalty=l1, score=0.8337285902503295, total=   0.0s\n",
      "[CV] C=333.34, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=333.34, class_weight=None, penalty=l1, score=0.852673796791444, total=   0.0s\n",
      "[CV] C=333.34, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=333.34, class_weight=None, penalty=l1, score=0.8378342245989305, total=   0.0s\n",
      "[CV] C=333.34, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=333.34, class_weight=None, penalty=l1, score=0.871424716675661, total=   0.0s\n",
      "[CV] C=333.34, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=333.34, class_weight=None, penalty=l2, score=0.8487483530961791, total=   0.0s\n",
      "[CV] C=333.34, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=333.34, class_weight=None, penalty=l2, score=0.8333333333333334, total=   0.0s\n",
      "[CV] C=333.34, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=333.34, class_weight=None, penalty=l2, score=0.8525401069518717, total=   0.0s\n",
      "[CV] C=333.34, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=333.34, class_weight=None, penalty=l2, score=0.8370320855614973, total=   0.0s\n",
      "[CV] C=333.34, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=333.34, class_weight=None, penalty=l2, score=0.871424716675661, total=   0.0s\n",
      "[CV] C=444.45, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=444.45, class_weight=balanced, penalty=l1, score=0.8459815546772068, total=   0.0s\n",
      "[CV] C=444.45, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=444.45, class_weight=balanced, penalty=l1, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=444.45, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=444.45, class_weight=balanced, penalty=l1, score=0.852139037433155, total=   0.0s\n",
      "[CV] C=444.45, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=444.45, class_weight=balanced, penalty=l1, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=444.45, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=444.45, class_weight=balanced, penalty=l1, score=0.8725040474905559, total=   0.0s\n",
      "[CV] C=444.45, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=444.45, class_weight=balanced, penalty=l2, score=0.8462450592885375, total=   0.0s\n",
      "[CV] C=444.45, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=444.45, class_weight=balanced, penalty=l2, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=444.45, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=444.45, class_weight=balanced, penalty=l2, score=0.852139037433155, total=   0.0s\n",
      "[CV] C=444.45, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=444.45, class_weight=balanced, penalty=l2, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=444.45, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=444.45, class_weight=balanced, penalty=l2, score=0.8725040474905559, total=   0.0s\n",
      "[CV] C=444.45, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=444.45, class_weight=None, penalty=l1, score=0.8486166007905137, total=   0.0s\n",
      "[CV] C=444.45, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=444.45, class_weight=None, penalty=l1, score=0.833201581027668, total=   0.0s\n",
      "[CV] C=444.45, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=444.45, class_weight=None, penalty=l1, score=0.852807486631016, total=   0.0s\n",
      "[CV] C=444.45, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=444.45, class_weight=None, penalty=l1, score=0.8378342245989305, total=   0.0s\n",
      "[CV] C=444.45, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=444.45, class_weight=None, penalty=l1, score=0.871424716675661, total=   0.0s\n",
      "[CV] C=444.45, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=444.45, class_weight=None, penalty=l2, score=0.8480895915678525, total=   0.0s\n",
      "[CV] C=444.45, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=444.45, class_weight=None, penalty=l2, score=0.8338603425559948, total=   0.0s\n",
      "[CV] C=444.45, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=444.45, class_weight=None, penalty=l2, score=0.8529411764705883, total=   0.0s\n",
      "[CV] C=444.45, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=444.45, class_weight=None, penalty=l2, score=0.8374331550802139, total=   0.0s\n",
      "[CV] C=444.45, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=444.45, class_weight=None, penalty=l2, score=0.8715596330275228, total=   0.0s\n",
      "[CV] C=555.56, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=555.56, class_weight=balanced, penalty=l1, score=0.8461133069828722, total=   0.0s\n",
      "[CV] C=555.56, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=555.56, class_weight=balanced, penalty=l1, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=555.56, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=555.56, class_weight=balanced, penalty=l1, score=0.8522727272727273, total=   0.0s\n",
      "[CV] C=555.56, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=555.56, class_weight=balanced, penalty=l1, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=555.56, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=555.56, class_weight=balanced, penalty=l1, score=0.8725040474905559, total=   0.0s\n",
      "[CV] C=555.56, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=555.56, class_weight=balanced, penalty=l2, score=0.8463768115942027, total=   0.0s\n",
      "[CV] C=555.56, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=555.56, class_weight=balanced, penalty=l2, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=555.56, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=555.56, class_weight=balanced, penalty=l2, score=0.852139037433155, total=   0.0s\n",
      "[CV] C=555.56, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=555.56, class_weight=balanced, penalty=l2, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=555.56, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=555.56, class_weight=balanced, penalty=l2, score=0.8725040474905559, total=   0.0s\n",
      "[CV] C=555.56, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=555.56, class_weight=None, penalty=l1, score=0.8482213438735178, total=   0.0s\n",
      "[CV] C=555.56, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=555.56, class_weight=None, penalty=l1, score=0.833201581027668, total=   0.0s\n",
      "[CV] C=555.56, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=555.56, class_weight=None, penalty=l1, score=0.852673796791444, total=   0.0s\n",
      "[CV] C=555.56, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=555.56, class_weight=None, penalty=l1, score=0.8377005347593582, total=   0.0s\n",
      "[CV] C=555.56, class_weight=None, penalty=l1 .........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=555.56, class_weight=None, penalty=l1, score=0.8716945493793847, total=   0.0s\n",
      "[CV] C=555.56, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=555.56, class_weight=None, penalty=l2, score=0.8480895915678525, total=   0.0s\n",
      "[CV] C=555.56, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=555.56, class_weight=None, penalty=l2, score=0.8333333333333334, total=   0.0s\n",
      "[CV] C=555.56, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=555.56, class_weight=None, penalty=l2, score=0.8525401069518717, total=   0.0s\n",
      "[CV] C=555.56, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=555.56, class_weight=None, penalty=l2, score=0.837433155080214, total=   0.0s\n",
      "[CV] C=555.56, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=555.56, class_weight=None, penalty=l2, score=0.8715596330275228, total=   0.0s\n",
      "[CV] C=666.67, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=666.67, class_weight=balanced, penalty=l1, score=0.8461133069828722, total=   0.0s\n",
      "[CV] C=666.67, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=666.67, class_weight=balanced, penalty=l1, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=666.67, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=666.67, class_weight=balanced, penalty=l1, score=0.852139037433155, total=   0.0s\n",
      "[CV] C=666.67, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=666.67, class_weight=balanced, penalty=l1, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=666.67, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=666.67, class_weight=balanced, penalty=l1, score=0.8725040474905559, total=   0.0s\n",
      "[CV] C=666.67, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=666.67, class_weight=balanced, penalty=l2, score=0.8463768115942027, total=   0.0s\n",
      "[CV] C=666.67, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=666.67, class_weight=balanced, penalty=l2, score=0.8326745718050066, total=   0.0s\n",
      "[CV] C=666.67, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=666.67, class_weight=balanced, penalty=l2, score=0.8520053475935829, total=   0.0s\n",
      "[CV] C=666.67, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=666.67, class_weight=balanced, penalty=l2, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=666.67, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=666.67, class_weight=balanced, penalty=l2, score=0.8725040474905559, total=   0.0s\n",
      "[CV] C=666.67, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=666.67, class_weight=None, penalty=l1, score=0.8483530961791831, total=   0.0s\n",
      "[CV] C=666.67, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=666.67, class_weight=None, penalty=l1, score=0.833201581027668, total=   0.0s\n",
      "[CV] C=666.67, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=666.67, class_weight=None, penalty=l1, score=0.852807486631016, total=   0.0s\n",
      "[CV] C=666.67, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=666.67, class_weight=None, penalty=l1, score=0.8378342245989305, total=   0.0s\n",
      "[CV] C=666.67, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=666.67, class_weight=None, penalty=l1, score=0.871424716675661, total=   0.0s\n",
      "[CV] C=666.67, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=666.67, class_weight=None, penalty=l2, score=0.8480895915678525, total=   0.0s\n",
      "[CV] C=666.67, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=666.67, class_weight=None, penalty=l2, score=0.8333333333333334, total=   0.0s\n",
      "[CV] C=666.67, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=666.67, class_weight=None, penalty=l2, score=0.8525401069518718, total=   0.0s\n",
      "[CV] C=666.67, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=666.67, class_weight=None, penalty=l2, score=0.8372994652406417, total=   0.0s\n",
      "[CV] C=666.67, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=666.67, class_weight=None, penalty=l2, score=0.8715596330275229, total=   0.0s\n",
      "[CV] C=777.78, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=777.78, class_weight=balanced, penalty=l1, score=0.8459815546772068, total=   0.0s\n",
      "[CV] C=777.78, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=777.78, class_weight=balanced, penalty=l1, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=777.78, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=777.78, class_weight=balanced, penalty=l1, score=0.852139037433155, total=   0.0s\n",
      "[CV] C=777.78, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=777.78, class_weight=balanced, penalty=l1, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=777.78, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=777.78, class_weight=balanced, penalty=l1, score=0.8722342147868322, total=   0.0s\n",
      "[CV] C=777.78, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=777.78, class_weight=balanced, penalty=l2, score=0.8459815546772069, total=   0.0s\n",
      "[CV] C=777.78, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=777.78, class_weight=balanced, penalty=l2, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=777.78, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=777.78, class_weight=balanced, penalty=l2, score=0.8520053475935829, total=   0.0s\n",
      "[CV] C=777.78, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=777.78, class_weight=balanced, penalty=l2, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=777.78, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=777.78, class_weight=balanced, penalty=l2, score=0.8720992984349702, total=   0.0s\n",
      "[CV] C=777.78, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=777.78, class_weight=None, penalty=l1, score=0.8482213438735178, total=   0.0s\n",
      "[CV] C=777.78, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=777.78, class_weight=None, penalty=l1, score=0.8337285902503295, total=   0.0s\n",
      "[CV] C=777.78, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=777.78, class_weight=None, penalty=l1, score=0.8522727272727273, total=   0.0s\n",
      "[CV] C=777.78, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=777.78, class_weight=None, penalty=l1, score=0.8378342245989305, total=   0.0s\n",
      "[CV] C=777.78, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=777.78, class_weight=None, penalty=l1, score=0.8716945493793847, total=   0.0s\n",
      "[CV] C=777.78, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=777.78, class_weight=None, penalty=l2, score=0.8480895915678525, total=   0.0s\n",
      "[CV] C=777.78, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=777.78, class_weight=None, penalty=l2, score=0.8333333333333334, total=   0.0s\n",
      "[CV] C=777.78, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=777.78, class_weight=None, penalty=l2, score=0.8526737967914438, total=   0.0s\n",
      "[CV] C=777.78, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=777.78, class_weight=None, penalty=l2, score=0.8372994652406417, total=   0.0s\n",
      "[CV] C=777.78, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=777.78, class_weight=None, penalty=l2, score=0.8716945493793847, total=   0.0s\n",
      "[CV] C=888.89, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=888.89, class_weight=balanced, penalty=l1, score=0.8459815546772069, total=   0.0s\n",
      "[CV] C=888.89, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=888.89, class_weight=balanced, penalty=l1, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=888.89, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=888.89, class_weight=balanced, penalty=l1, score=0.852139037433155, total=   0.0s\n",
      "[CV] C=888.89, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=888.89, class_weight=balanced, penalty=l1, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=888.89, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=888.89, class_weight=balanced, penalty=l1, score=0.8722342147868322, total=   0.0s\n",
      "[CV] C=888.89, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=888.89, class_weight=balanced, penalty=l2, score=0.8459815546772069, total=   0.0s\n",
      "[CV] C=888.89, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=888.89, class_weight=balanced, penalty=l2, score=0.8329380764163372, total=   0.0s\n",
      "[CV] C=888.89, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=888.89, class_weight=balanced, penalty=l2, score=0.852139037433155, total=   0.0s\n",
      "[CV] C=888.89, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=888.89, class_weight=balanced, penalty=l2, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=888.89, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=888.89, class_weight=balanced, penalty=l2, score=0.8725040474905559, total=   0.0s\n",
      "[CV] C=888.89, class_weight=None, penalty=l1 .........................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=888.89, class_weight=None, penalty=l1, score=0.8482213438735178, total=   0.0s\n",
      "[CV] C=888.89, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=888.89, class_weight=None, penalty=l1, score=0.833201581027668, total=   0.0s\n",
      "[CV] C=888.89, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=888.89, class_weight=None, penalty=l1, score=0.852673796791444, total=   0.0s\n",
      "[CV] C=888.89, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=888.89, class_weight=None, penalty=l1, score=0.8381016042780748, total=   0.0s\n",
      "[CV] C=888.89, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=888.89, class_weight=None, penalty=l1, score=0.871424716675661, total=   0.0s\n",
      "[CV] C=888.89, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=888.89, class_weight=None, penalty=l2, score=0.8488801054018444, total=   0.0s\n",
      "[CV] C=888.89, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=888.89, class_weight=None, penalty=l2, score=0.8333333333333334, total=   0.0s\n",
      "[CV] C=888.89, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=888.89, class_weight=None, penalty=l2, score=0.8525401069518718, total=   0.0s\n",
      "[CV] C=888.89, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=888.89, class_weight=None, penalty=l2, score=0.8368983957219251, total=   0.0s\n",
      "[CV] C=888.89, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=888.89, class_weight=None, penalty=l2, score=0.8716945493793847, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=1000.0, class_weight=balanced, penalty=l1, score=0.8461133069828722, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=1000.0, class_weight=balanced, penalty=l1, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=1000.0, class_weight=balanced, penalty=l1, score=0.8521390374331552, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=1000.0, class_weight=balanced, penalty=l1, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=balanced, penalty=l1 .....................\n",
      "[CV]  C=1000.0, class_weight=balanced, penalty=l1, score=0.8722342147868322, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=1000.0, class_weight=balanced, penalty=l2, score=0.8459815546772069, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=1000.0, class_weight=balanced, penalty=l2, score=0.8328063241106719, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=1000.0, class_weight=balanced, penalty=l2, score=0.8524064171122995, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=1000.0, class_weight=balanced, penalty=l2, score=0.8342245989304813, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=balanced, penalty=l2 .....................\n",
      "[CV]  C=1000.0, class_weight=balanced, penalty=l2, score=0.8722342147868322, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=1000.0, class_weight=None, penalty=l1, score=0.8482213438735178, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=1000.0, class_weight=None, penalty=l1, score=0.833596837944664, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=1000.0, class_weight=None, penalty=l1, score=0.8526737967914438, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=1000.0, class_weight=None, penalty=l1, score=0.8374331550802139, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=None, penalty=l1 .........................\n",
      "[CV]  C=1000.0, class_weight=None, penalty=l1, score=0.8716945493793847, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=1000.0, class_weight=None, penalty=l2, score=0.8482213438735178, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=1000.0, class_weight=None, penalty=l2, score=0.8333333333333334, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=1000.0, class_weight=None, penalty=l2, score=0.8529411764705883, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=1000.0, class_weight=None, penalty=l2, score=0.8372994652406417, total=   0.0s\n",
      "[CV] C=1000.0, class_weight=None, penalty=l2 .........................\n",
      "[CV]  C=1000.0, class_weight=None, penalty=l2, score=0.8712898003237992, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'class_weight': ['balanced', None], 'penalty': ['l1', 'l2'], 'C': array([1.0000e-02, 1.1112e+02, 2.2223e+02, 3.3334e+02, 4.4445e+02,\n",
       "       5.5556e+02, 6.6667e+02, 7.7778e+02, 8.8889e+02, 1.0000e+03])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=111.12, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.849 (std: 0.013)\n",
      "Parameters: {'C': 111.12, 'class_weight': None, 'penalty': 'l2'}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.849 (std: 0.013)\n",
      "Parameters: {'C': 333.34, 'class_weight': None, 'penalty': 'l1'}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.849 (std: 0.013)\n",
      "Parameters: {'C': 444.45, 'class_weight': None, 'penalty': 'l1'}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.849 (std: 0.013)\n",
      "Parameters: {'C': 444.45, 'class_weight': None, 'penalty': 'l2'}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.849 (std: 0.013)\n",
      "Parameters: {'C': 777.78, 'class_weight': None, 'penalty': 'l1'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(grid_search.cv_results_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=111.12, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21, 0.22,\n",
       "       0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32, 0.33,\n",
       "       0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43, 0.44,\n",
       "       0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54, 0.55,\n",
       "       0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65, 0.66,\n",
       "       0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77,\n",
       "       0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88,\n",
       "       0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoffs=np.linspace(0.01,0.99,99)\n",
    "\n",
    "cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08542873, 0.91905002, 0.62263717, 0.88937467, 0.0720895 ,\n",
       "       0.11893708, 0.26043777, 0.09128404, 0.56902081, 0.90018137,\n",
       "       0.72322721, 0.81079107, 0.12232905, 0.03048691, 0.72487241,\n",
       "       0.61549092, 0.09493617, 0.22147132, 0.5022633 , 0.68606623,\n",
       "       0.19211619, 0.19402742, 0.78182326, 0.48401669, 0.54395653,\n",
       "       0.32892094, 0.12746661, 0.40249333, 0.66922609, 0.08734237,\n",
       "       0.46966339, 0.948356  , 0.66925798, 0.06458043, 0.53452832,\n",
       "       0.29048281, 0.12758158, 0.11847979, 0.54919342, 0.74714392,\n",
       "       0.41182626, 0.77788148, 0.12780282, 0.92152188, 0.75447604,\n",
       "       0.08749847, 0.09084452, 0.66959811, 0.07374092, 0.62659769,\n",
       "       0.05899868, 0.11857593, 0.88266668, 0.76621468, 0.24658504,\n",
       "       0.46834521, 0.85647044, 0.13311376, 0.87367018, 0.03474248,\n",
       "       0.16513851, 0.93665606, 0.28044599, 0.07931433, 0.57023146,\n",
       "       0.08962913, 0.8139712 , 0.12721744, 0.35169972, 0.05541177,\n",
       "       0.20646733, 0.30752917, 0.31248478, 0.11111072, 0.088551  ,\n",
       "       0.10344917, 0.08772703, 0.08776063, 0.4290194 , 0.58961342,\n",
       "       0.11512224, 0.09024117, 0.67040811, 0.49151522, 0.8748772 ,\n",
       "       0.33062379, 0.08631331, 0.0878427 , 0.89674589, 0.10733015,\n",
       "       0.09007212, 0.12315731, 0.26425598, 0.06412337, 0.02984928,\n",
       "       0.0879084 , 0.21304316, 0.62821202, 0.77115883, 0.15331512,\n",
       "       0.60657039, 0.08793226, 0.55153548, 0.07828936, 0.0369017 ,\n",
       "       0.09341567, 0.66938342, 0.08796165, 0.06528878, 0.6051428 ,\n",
       "       0.3185627 , 0.74610947, 0.11525724, 0.60586873, 0.78592421,\n",
       "       0.11929007, 0.02711497, 0.17906057, 0.7040527 , 0.506334  ,\n",
       "       0.19424644, 0.08812225, 0.22880512, 0.79426405, 0.25447254,\n",
       "       0.17711951, 0.12008844, 0.10752434, 0.60084138, 0.05052073,\n",
       "       0.11507212, 0.12342151, 0.35228144, 0.76767988, 0.25687373,\n",
       "       0.36459303, 0.94233462, 0.33497347, 0.14189903, 0.64979564,\n",
       "       0.65010188, 0.66156581, 0.57192418, 0.17141873, 0.31174527,\n",
       "       0.23255212, 0.09711324, 0.59898906, 0.15805498, 0.15158617,\n",
       "       0.11172122, 0.93296409, 0.03430634, 0.05060861, 0.08827217,\n",
       "       0.36284103, 0.7773925 , 0.08748004, 0.08852901, 0.00700758,\n",
       "       0.04887994, 0.74432083, 0.10072338, 0.13739529, 0.07417294,\n",
       "       0.15545919, 0.92656992, 0.29266797, 0.46632396, 0.1028379 ,\n",
       "       0.20799779, 0.08974617, 0.74694865, 0.11991587, 0.32669316,\n",
       "       0.09182434, 0.03391229, 0.90137203, 0.22229832, 0.06961838,\n",
       "       0.09573635, 0.30758705, 0.04990686, 0.30904798, 0.77086977,\n",
       "       0.47910289, 0.60277347, 0.32584615, 0.05812778, 0.07074525,\n",
       "       0.79853172, 0.30513131, 0.61607696, 0.35695759, 0.92024826,\n",
       "       0.89524693, 0.12084843, 0.0520304 , 0.6730122 , 0.84413799,\n",
       "       0.09452544, 0.00703759, 0.07592651, 0.07445265, 0.13318766,\n",
       "       0.79657367, 0.06174135, 0.1496588 , 0.77831915, 0.47591675,\n",
       "       0.10832499, 0.78228341, 0.11613721, 0.22291896, 0.09094952,\n",
       "       0.94322434, 0.61863888, 0.11857809, 0.95324847, 0.2221355 ,\n",
       "       0.14263144, 0.24394218, 0.04088496, 0.08894003, 0.34527891,\n",
       "       0.11671869, 0.30480132, 0.12242891, 0.31425968, 0.34570094,\n",
       "       0.89753401, 0.09121639, 0.08516519, 0.48014049, 0.26536495,\n",
       "       0.59385567, 0.11067202, 0.8958418 , 0.30506193, 0.20354335,\n",
       "       0.62240995, 0.60412209, 0.22934772, 0.11643722, 0.12865364,\n",
       "       0.30040029, 0.63746085, 0.81848912, 0.31623538, 0.07786875,\n",
       "       0.08905663, 0.49990976, 0.20071325, 0.06673738, 0.44448061,\n",
       "       0.65891741, 0.95748418, 0.93662302, 0.97810704, 0.64907494,\n",
       "       0.12154691, 0.06268797, 0.21456949, 0.35908987, 0.67449874,\n",
       "       0.18512383, 0.04321106, 0.07877824, 0.83848335, 0.93092214,\n",
       "       0.47152686, 0.10385289, 0.72174323, 0.48215844, 0.67472367,\n",
       "       0.74533821, 0.4474901 , 0.22145354, 0.08147267, 0.44749031,\n",
       "       0.0339158 , 0.09494687, 0.14377694, 0.12967014, 0.46932163,\n",
       "       0.11686205, 0.08878203, 0.11706567, 0.15342704, 0.73705892,\n",
       "       0.94461472, 0.96228456, 0.25928418, 0.64800877, 0.10932851,\n",
       "       0.57602233, 0.16047962, 0.96801129, 0.47198551, 0.92953802,\n",
       "       0.67530811, 0.07038348, 0.12802974, 0.86083044, 0.08964076,\n",
       "       0.67844772, 0.96025589, 0.96628001, 0.24764243, 0.95531225,\n",
       "       0.96610033, 0.95778632, 0.77464465, 0.09523639, 0.10601763,\n",
       "       0.63010881, 0.80353844, 0.1024897 , 0.93280135, 0.91824421,\n",
       "       0.11727802, 0.09871525, 0.859657  , 0.80181309, 0.00712621,\n",
       "       0.95223123, 0.02826604, 0.77478688, 0.48760519, 0.9711308 ,\n",
       "       0.53200963, 0.32569506, 0.43184893, 0.0831273 , 0.92345609,\n",
       "       0.08987436, 0.41913361, 0.94250178, 0.05166621, 0.33335602,\n",
       "       0.36943978, 0.89553731, 0.23908582, 0.26098302, 0.18712918,\n",
       "       0.84609619, 0.7468435 , 0.52235351, 0.15794067, 0.05782415,\n",
       "       0.11402856, 0.47564757, 0.15016426, 0.08094119, 0.13125166,\n",
       "       0.09589362, 0.94553525, 0.76147713, 0.67666804, 0.67669046,\n",
       "       0.03311187, 0.25745658, 0.53515478, 0.07444739, 0.09357188,\n",
       "       0.08906283, 0.83466417, 0.69369683, 0.67683405, 0.96535683,\n",
       "       0.55835859, 0.10168245, 0.13070283, 0.69763019, 0.60029514,\n",
       "       0.94338595, 0.66670755, 0.64720441, 0.17994884, 0.13072005,\n",
       "       0.95043617, 0.85344554, 0.08318633, 0.89293182, 0.0902859 ,\n",
       "       0.34530854, 0.05206344, 0.77585786, 0.12294969, 0.91711606,\n",
       "       0.337487  , 0.1222649 , 0.05304067, 0.95850157, 0.60959072,\n",
       "       0.11819294, 0.58575246, 0.13875163, 0.27636733, 0.82541557,\n",
       "       0.06474597, 0.10301568, 0.60364657, 0.07274654, 0.68501726,\n",
       "       0.15607007, 0.04160611, 0.35856891, 0.12244737, 0.34988467,\n",
       "       0.09050496, 0.12301063, 0.93247257, 0.22386553, 0.0539896 ,\n",
       "       0.59854364, 0.7206071 , 0.85244882, 0.2265789 , 0.73267178,\n",
       "       0.13218294, 0.16480303, 0.09286914, 0.516063  , 0.09616153,\n",
       "       0.09052212, 0.7797465 , 0.87369177, 0.12339698, 0.08357406,\n",
       "       0.48983557, 0.52450061, 0.67262123, 0.14032525, 0.23950192,\n",
       "       0.94745819, 0.49098795, 0.68991329, 0.16028801, 0.21932029,\n",
       "       0.62458755, 0.12745895, 0.08008947, 0.82616776, 0.09082896,\n",
       "       0.69366165, 0.88699773, 0.43232257, 0.74590813, 0.2759921 ,\n",
       "       0.12583568, 0.06926915, 0.57710636, 0.34942256, 0.09090298,\n",
       "       0.13575494, 0.18577976, 0.91170246, 0.66798398, 0.12374099,\n",
       "       0.30665822, 0.07803937, 0.32036615, 0.12747186, 0.0909877 ,\n",
       "       0.06744747, 0.22481055, 0.24483497, 0.12383544, 0.77633346,\n",
       "       0.09090246, 0.06769522, 0.70821876, 0.89867844, 0.67011302,\n",
       "       0.48755086, 0.1570307 , 0.06948122, 0.11902289, 0.801683  ,\n",
       "       0.03903525, 0.22507852, 0.04353424, 0.29189345, 0.57920269,\n",
       "       0.35165813, 0.90112394, 0.31626803, 0.09022568, 0.13094341,\n",
       "       0.06952723, 0.12324743, 0.2541208 , 0.22522931, 0.12345864,\n",
       "       0.13463221, 0.86669388, 0.09247784, 0.92659515, 0.11137046,\n",
       "       0.14153939, 0.74863981, 0.67977595, 0.53183277, 0.96314561,\n",
       "       0.65264491, 0.76961749, 0.47529864, 0.09963975, 0.11370692,\n",
       "       0.12730031, 0.09138681, 0.4148185 , 0.86235218, 0.11146153,\n",
       "       0.31954276, 0.79044073, 0.12810839, 0.72358942, 0.08425862,\n",
       "       0.93903371, 0.11956686, 0.13322704, 0.92027467, 0.13325171,\n",
       "       0.08541329, 0.66952751, 0.57561717, 0.06554474, 0.15686846,\n",
       "       0.8994297 , 0.13333457, 0.14274335, 0.66248534, 0.59896322,\n",
       "       0.90214588, 0.33375025, 0.96036226, 0.09272713, 0.96048271,\n",
       "       0.90598989, 0.44922781, 0.43008395, 0.1700155 , 0.3507988 ,\n",
       "       0.1929786 , 0.83571375, 0.31510402, 0.0567368 , 0.32639201,\n",
       "       0.69138501, 0.25528379, 0.12479578, 0.17222022, 0.67098657,\n",
       "       0.20574048, 0.88412609, 0.67795024, 0.8748586 , 0.46722309,\n",
       "       0.12486753, 0.06339839, 0.24340039, 0.09183021, 0.60220673,\n",
       "       0.0644376 , 0.13294151, 0.52162774, 0.13377329, 0.08464814,\n",
       "       0.07853514, 0.75386566, 0.41636168, 0.68141151, 0.14712502,\n",
       "       0.13462285, 0.79230494, 0.88009252, 0.63051633, 0.08473887,\n",
       "       0.78740044, 0.91952398, 0.10735759, 0.5290493 , 0.13431782,\n",
       "       0.95204788, 0.13378824, 0.24015391, 0.12032505, 0.09205264,\n",
       "       0.07607693, 0.87648881, 0.04910973, 0.63901941, 0.14494127,\n",
       "       0.05139856, 0.82482964, 0.04497784, 0.1341289 , 0.33786761,\n",
       "       0.73586644, 0.09212892, 0.48586791, 0.05500068, 0.53232044,\n",
       "       0.05538628, 0.09119683, 0.50612715, 0.85592036, 0.92257868,\n",
       "       0.33352892, 0.0920691 , 0.61317693, 0.1254622 , 0.07638412,\n",
       "       0.79054699, 0.05439949, 0.56489997, 0.86168137, 0.25795254,\n",
       "       0.11281487, 0.30325321, 0.13208086, 0.1248522 , 0.12672893,\n",
       "       0.21537254, 0.12864066, 0.95537077, 0.10515508, 0.12563842,\n",
       "       0.11543464, 0.04247695, 0.56394483, 0.46490877, 0.52954437,\n",
       "       0.8289751 , 0.08519296, 0.16354788, 0.39403301, 0.07000181,\n",
       "       0.12936216, 0.96627694, 0.59664495, 0.1012306 , 0.77943172,\n",
       "       0.35698977, 0.13388926, 0.33965573, 0.09247281, 0.66441064,\n",
       "       0.09254974, 0.86922128, 0.12530778, 0.6832237 , 0.77236633,\n",
       "       0.18473966, 0.09260139, 0.56958727, 0.28276891, 0.31591303,\n",
       "       0.21554488, 0.09455143, 0.3190457 , 0.0739492 , 0.09765769,\n",
       "       0.14248338, 0.26741681, 0.09267524, 0.05741783, 0.913458  ,\n",
       "       0.67992221, 0.40134581, 0.05934287, 0.22434704, 0.22854661,\n",
       "       0.13879116, 0.11129179, 0.70788744, 0.28814784, 0.73145645,\n",
       "       0.68395929, 0.6345683 , 0.13016662, 0.03301498, 0.06126026,\n",
       "       0.26248651, 0.0484929 , 0.13492254, 0.13895557, 0.97018054,\n",
       "       0.4042886 , 0.85417626, 0.10168833, 0.1581101 , 0.22119231,\n",
       "       0.11361478, 0.05549809, 0.68415605, 0.34360497, 0.05969228,\n",
       "       0.97342291, 0.4290313 , 0.77316342, 0.14809219, 0.07921707,\n",
       "       0.17920143, 0.71610349, 0.36411229, 0.9602468 , 0.09516139,\n",
       "       0.96516287, 0.48051425, 0.2578584 , 0.09569779, 0.11370728,\n",
       "       0.13465234, 0.95866091, 0.83487099, 0.12842153, 0.08282958,\n",
       "       0.91595802, 0.10883018, 0.20550764, 0.12188735, 0.44114242,\n",
       "       0.13053491, 0.63825148, 0.6848218 , 0.21514431, 0.57313189,\n",
       "       0.95423476, 0.2497518 , 0.22959616, 0.28433012, 0.28435098,\n",
       "       0.09879848, 0.30323   , 0.75813471, 0.09330983, 0.0933185 ,\n",
       "       0.48302821, 0.37005062, 0.95475291, 0.08672838, 0.0891695 ,\n",
       "       0.12278882, 0.10624068, 0.81936296, 0.51929349, 0.12149241,\n",
       "       0.89373326, 0.1920736 , 0.08335759, 0.11798249, 0.60075905,\n",
       "       0.3860361 , 0.0992019 , 0.32537914, 0.08025731, 0.93263505,\n",
       "       0.09465869, 0.06222101, 0.18683188, 0.8879294 , 0.14951284,\n",
       "       0.83076111, 0.59367219, 0.67895697, 0.09871459, 0.08633207,\n",
       "       0.11450347, 0.0482151 , 0.61274986, 0.13622518, 0.49880239,\n",
       "       0.14001428, 0.12730629, 0.80323546, 0.1273262 , 0.91698451,\n",
       "       0.81899325, 0.9464698 , 0.49089927, 0.06020028, 0.11026283,\n",
       "       0.11031326, 0.70919729, 0.08246946, 0.16291328, 0.4572857 ,\n",
       "       0.12746575, 0.35023074, 0.10130459, 0.58991528, 0.11053436,\n",
       "       0.17663852, 0.86812815, 0.59609706, 0.13515362, 0.51125827,\n",
       "       0.20681569, 0.7485318 , 0.58430069, 0.31053412, 0.10303167,\n",
       "       0.08965327, 0.38112724, 0.70975922, 0.17683234, 0.90419921,\n",
       "       0.10692126, 0.06947042, 0.19987893, 0.48520686, 0.0913773 ,\n",
       "       0.469551  , 0.66838634, 0.23742871, 0.05807504, 0.06864489,\n",
       "       0.81669708, 0.10351449, 0.39073662, 0.61295043, 0.07616938,\n",
       "       0.12768173, 0.10294948, 0.55611606, 0.12789944, 0.86278215,\n",
       "       0.75624257, 0.38848147, 0.13693914, 0.11882925, 0.14088072,\n",
       "       0.91719908, 0.12744136, 0.09419868, 0.09507625, 0.5905598 ,\n",
       "       0.13170455, 0.34416462, 0.9553665 , 0.11626835, 0.1458767 ,\n",
       "       0.06052584, 0.00751482, 0.11462986, 0.23861173, 0.94664983,\n",
       "       0.06394599, 0.01822993, 0.78141459, 0.95715967, 0.66496203,\n",
       "       0.69142104, 0.87180454, 0.29073038, 0.69581848, 0.13726645,\n",
       "       0.03464471, 0.23962194, 0.87326952, 0.10196886, 0.27917256,\n",
       "       0.74215676, 0.85168429, 0.48416747, 0.09472557, 0.15856267,\n",
       "       0.10751139, 0.83336508, 0.44170208, 0.05064474, 0.84949515,\n",
       "       0.80867868, 0.13258076, 0.13665798, 0.09453061, 0.88769843,\n",
       "       0.83907451, 0.08411856, 0.67959267, 0.2483548 , 0.11127211,\n",
       "       0.49907534, 0.2567279 , 0.95561731, 0.49220692, 0.62620102,\n",
       "       0.11890562])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score=logr.predict_proba(x_train)[:,1]\n",
    "\n",
    "real=y_train\n",
    "\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0\n",
       "1      1.0\n",
       "2      1.0\n",
       "3      1.0\n",
       "4      0.0\n",
       "      ... \n",
       "886    0.0\n",
       "887    1.0\n",
       "888    0.0\n",
       "889    1.0\n",
       "890    0.0\n",
       "Name: Survived, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True, False, False,  True, False,  True,\n",
       "        True,  True,  True, False, False,  True,  True, False,  True,\n",
       "        True,  True, False, False,  True,  True,  True,  True, False,\n",
       "        True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "       False, False,  True,  True,  True,  True, False,  True,  True,\n",
       "       False, False,  True, False,  True, False, False,  True,  True,\n",
       "        True,  True,  True, False,  True, False, False,  True,  True,\n",
       "       False,  True, False,  True, False,  True, False,  True,  True,\n",
       "        True, False, False, False, False, False,  True,  True, False,\n",
       "       False,  True,  True,  True,  True, False, False,  True, False,\n",
       "       False, False,  True, False, False, False,  True,  True,  True,\n",
       "       False,  True, False,  True, False, False, False,  True, False,\n",
       "       False,  True,  True,  True, False,  True,  True, False, False,\n",
       "       False,  True,  True, False, False,  True,  True,  True, False,\n",
       "       False, False,  True, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "        True,  True, False,  True, False, False, False,  True, False,\n",
       "       False, False,  True,  True, False, False, False, False,  True,\n",
       "       False, False, False, False,  True,  True,  True, False,  True,\n",
       "       False,  True, False,  True, False, False,  True,  True, False,\n",
       "       False,  True, False,  True,  True,  True,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        True,  True, False, False, False, False, False,  True, False,\n",
       "       False,  True,  True, False,  True, False,  True, False,  True,\n",
       "        True, False,  True,  True, False,  True, False, False,  True,\n",
       "       False,  True, False,  True,  True,  True, False, False,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True, False, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "       False,  True,  True,  True, False, False, False,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "       False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "        True,  True,  True,  True, False, False,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        True,  True, False,  True,  True, False, False,  True,  True,\n",
       "       False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True, False,  True,  True, False,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True, False, False, False,\n",
       "        True, False, False, False, False,  True,  True,  True,  True,\n",
       "       False,  True,  True, False, False, False,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True, False,  True, False,  True, False,\n",
       "        True, False,  True,  True, False, False,  True,  True, False,\n",
       "        True, False,  True,  True, False, False,  True, False,  True,\n",
       "       False, False,  True, False,  True, False, False,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True, False, False, False,\n",
       "        True, False, False,  True,  True, False, False,  True,  True,\n",
       "        True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "       False, False,  True, False,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True, False, False, False,  True,  True,\n",
       "       False,  True, False,  True, False, False, False,  True,  True,\n",
       "       False,  True, False, False,  True,  True,  True,  True, False,\n",
       "       False, False,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True, False, False, False, False,  True,  True, False,\n",
       "       False,  True, False,  True, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False, False, False,  True,\n",
       "        True, False,  True,  True, False,  True, False,  True, False,\n",
       "       False,  True, False, False,  True,  True, False, False,  True,\n",
       "       False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True, False,  True, False,  True,  True, False,\n",
       "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        True,  True, False, False,  True, False,  True, False, False,\n",
       "        True, False, False, False,  True,  True,  True, False, False,\n",
       "        True,  True,  True, False,  True,  True, False,  True, False,\n",
       "        True, False,  True, False, False, False,  True, False,  True,\n",
       "       False, False,  True, False, False,  True,  True, False,  True,\n",
       "       False,  True, False, False,  True,  True,  True,  True, False,\n",
       "        True, False, False,  True, False,  True,  True,  True, False,\n",
       "        True, False, False, False,  True, False,  True, False, False,\n",
       "       False, False,  True,  True,  True,  True, False, False,  True,\n",
       "       False, False,  True,  True, False,  True,  True, False,  True,\n",
       "       False,  True, False,  True, False,  True,  True, False, False,\n",
       "        True,  True,  True,  True, False,  True, False, False, False,\n",
       "        True, False, False,  True,  True,  True, False,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True, False, False,\n",
       "       False,  True, False, False, False,  True,  True,  True, False,\n",
       "       False,  True, False, False,  True,  True, False,  True,  True,\n",
       "        True, False, False, False,  True,  True,  True, False,  True,\n",
       "        True,  True, False, False, False,  True,  True, False, False,\n",
       "        True, False,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "       False, False,  True,  True,  True, False, False, False, False,\n",
       "        True,  True, False,  True, False, False, False,  True,  True,\n",
       "       False,  True, False,  True, False, False, False,  True, False,\n",
       "        True,  True,  True, False, False, False, False,  True, False,\n",
       "        True, False, False,  True, False,  True,  True,  True,  True,\n",
       "       False, False, False,  True, False, False,  True, False,  True,\n",
       "       False,  True, False, False,  True,  True, False,  True,  True,\n",
       "        True,  True,  True, False, False,  True,  True, False,  True,\n",
       "       False, False, False,  True, False,  True,  True,  True, False,\n",
       "       False,  True, False,  True,  True, False, False, False,  True,\n",
       "       False,  True,  True,  True, False, False, False,  True, False,\n",
       "       False, False,  True, False,  True,  True, False, False, False,\n",
       "       False, False,  True,  True, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False,  True,  True, False,\n",
       "        True,  True,  True,  True, False, False, False,  True,  True,\n",
       "       False,  True,  True, False, False, False,  True,  True, False,\n",
       "        True,  True, False,  True,  True,  True,  True,  True, False])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score>0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS_all=[]\n",
    "A_all=[]\n",
    "for cutoff in cutoffs:\n",
    "    \n",
    "    predicted=(train_score>cutoff).astype(int)\n",
    "\n",
    "    TP=((predicted==1) & (real==1)).sum()\n",
    "    TN=((predicted==0) & (real==0)).sum()\n",
    "    FP=((predicted==1) & (real==0)).sum()\n",
    "    FN=((predicted==0) & (real==1)).sum()\n",
    "    \n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "    Accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
    "    KS=(TP/P)-(FP/N)\n",
    "    \n",
    "    A_all.append(Accuracy)\n",
    "    KS_all.append(KS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.388327721661055,\n",
       " 0.3894500561167228,\n",
       " 0.39281705948372614,\n",
       " 0.40404040404040403,\n",
       " 0.4163860830527497,\n",
       " 0.43658810325476993,\n",
       " 0.45791245791245794,\n",
       " 0.47474747474747475,\n",
       " 0.5061728395061729,\n",
       " 0.5544332210998878,\n",
       " 0.569023569023569,\n",
       " 0.6094276094276094,\n",
       " 0.6520763187429854,\n",
       " 0.6823793490460157,\n",
       " 0.6947250280583613,\n",
       " 0.6992143658810326,\n",
       " 0.7037037037037037,\n",
       " 0.7070707070707071,\n",
       " 0.7104377104377104,\n",
       " 0.712682379349046,\n",
       " 0.7205387205387206,\n",
       " 0.7250280583613917,\n",
       " 0.7384960718294051,\n",
       " 0.745230078563412,\n",
       " 0.7519640852974186,\n",
       " 0.7598204264870931,\n",
       " 0.7665544332210998,\n",
       " 0.7676767676767676,\n",
       " 0.7732884399551067,\n",
       " 0.7732884399551067,\n",
       " 0.7755331088664422,\n",
       " 0.7811447811447811,\n",
       " 0.7822671156004489,\n",
       " 0.7822671156004489,\n",
       " 0.7856341189674523,\n",
       " 0.7867564534231201,\n",
       " 0.7867564534231201,\n",
       " 0.7878787878787878,\n",
       " 0.7867564534231201,\n",
       " 0.7890011223344556,\n",
       " 0.7901234567901234,\n",
       " 0.7901234567901234,\n",
       " 0.7878787878787878,\n",
       " 0.7890011223344556,\n",
       " 0.7912457912457912,\n",
       " 0.792368125701459,\n",
       " 0.7957351290684624,\n",
       " 0.7957351290684624,\n",
       " 0.7968574635241302,\n",
       " 0.8024691358024691,\n",
       " 0.8035914702581369,\n",
       " 0.8069584736251403,\n",
       " 0.8080808080808081,\n",
       " 0.8092031425364759,\n",
       " 0.8114478114478114,\n",
       " 0.8103254769921436,\n",
       " 0.8103254769921436,\n",
       " 0.813692480359147,\n",
       " 0.813692480359147,\n",
       " 0.8181818181818182,\n",
       " 0.8170594837261503,\n",
       " 0.8125701459034792,\n",
       " 0.8103254769921436,\n",
       " 0.8103254769921436,\n",
       " 0.8125701459034792,\n",
       " 0.813692480359147,\n",
       " 0.8047138047138047,\n",
       " 0.7991021324354658,\n",
       " 0.7946127946127947,\n",
       " 0.7901234567901234,\n",
       " 0.7890011223344556,\n",
       " 0.7878787878787878,\n",
       " 0.7845117845117845,\n",
       " 0.7822671156004489,\n",
       " 0.7755331088664422,\n",
       " 0.7710437710437711,\n",
       " 0.7687991021324355,\n",
       " 0.7631874298540965,\n",
       " 0.7620650953984287,\n",
       " 0.7575757575757576,\n",
       " 0.7519640852974186,\n",
       " 0.745230078563412,\n",
       " 0.7407407407407407,\n",
       " 0.7328843995510662,\n",
       " 0.7317620650953984,\n",
       " 0.7239057239057239,\n",
       " 0.7160493827160493,\n",
       " 0.7081930415263749,\n",
       " 0.7003367003367004,\n",
       " 0.6902356902356902,\n",
       " 0.6857463524130191,\n",
       " 0.675645342312009,\n",
       " 0.6689113355780022,\n",
       " 0.6599326599326599,\n",
       " 0.6487093153759821,\n",
       " 0.6318742985409652,\n",
       " 0.6206509539842873,\n",
       " 0.6161616161616161,\n",
       " 0.6161616161616161]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.007285974499089298,\n",
       " 0.00910746812386154,\n",
       " 0.014571948998178486,\n",
       " 0.032786885245901676,\n",
       " 0.05282331511839711,\n",
       " 0.08340523439746905,\n",
       " 0.11580864730131335,\n",
       " 0.1398236027226536,\n",
       " 0.18200556034895976,\n",
       " 0.2537148883136804,\n",
       " 0.27077940753523155,\n",
       " 0.3341482120602052,\n",
       " 0.3978525548844789,\n",
       " 0.44262295081967207,\n",
       " 0.46045441472533793,\n",
       " 0.4633304572907679,\n",
       " 0.46951394880644237,\n",
       " 0.47167098073051483,\n",
       " 0.47603297862141697,\n",
       " 0.4774709999041319,\n",
       " 0.4902214552775381,\n",
       " 0.49640494679321256,\n",
       " 0.5160579043236506,\n",
       " 0.5269868660722845,\n",
       " 0.5368133448375036,\n",
       " 0.548461317227495,\n",
       " 0.5593902789761289,\n",
       " 0.5601092896174864,\n",
       " 0.569216757741348,\n",
       " 0.5670117917745183,\n",
       " 0.5662448470904036,\n",
       " 0.5720448662640206,\n",
       " 0.5705589109385486,\n",
       " 0.5661489790048893,\n",
       " 0.5694084939123766,\n",
       " 0.5668200556034896,\n",
       " 0.56461508963666,\n",
       " 0.5664365832614323,\n",
       " 0.5624101236698302,\n",
       " 0.5660531109193749,\n",
       " 0.5667721215607324,\n",
       " 0.5645671555939027,\n",
       " 0.5587192023775285,\n",
       " 0.5594382130188861,\n",
       " 0.5608762343016009,\n",
       " 0.5626977279263733,\n",
       " 0.5659572428338606,\n",
       " 0.5626497938836161,\n",
       " 0.5589588725913144,\n",
       " 0.5669638577317611,\n",
       " 0.5676828683731185,\n",
       " 0.5731473492474355,\n",
       " 0.5727638769053782,\n",
       " 0.5723804045633208,\n",
       " 0.5760233918128654,\n",
       " 0.5719969322212636,\n",
       " 0.5697919662544338,\n",
       " 0.5730514811619213,\n",
       " 0.5708465151950916,\n",
       " 0.5759275237273512,\n",
       " 0.5674911322020899,\n",
       " 0.5546927427859266,\n",
       " 0.5466398236027227,\n",
       " 0.5433323746524782,\n",
       " 0.545872878918608,\n",
       " 0.5465918895599655,\n",
       " 0.5209951107276387,\n",
       " 0.49976032978621415,\n",
       " 0.485859457386636,\n",
       " 0.4730610679704727,\n",
       " 0.4679321253954558,\n",
       " 0.4650081487872687,\n",
       " 0.4551337359792925,\n",
       " 0.4481832997795034,\n",
       " 0.4284344741635509,\n",
       " 0.41673856773080237,\n",
       " 0.40978813153101334,\n",
       " 0.39075831655641835,\n",
       " 0.3856293739814016,\n",
       " 0.3728309845652382,\n",
       " 0.3582111015243026,\n",
       " 0.34066724187517977,\n",
       " 0.32897133544243123,\n",
       " 0.30850349918512127,\n",
       " 0.3044770395935193,\n",
       " 0.2840092033362094,\n",
       " 0.2635413670788994,\n",
       " 0.24307353082158947,\n",
       " 0.22260569456427953,\n",
       " 0.19628990509059532,\n",
       " 0.18349151567443198,\n",
       " 0.15717572620074777,\n",
       " 0.13852938356821012,\n",
       " 0.11513757070271306,\n",
       " 0.08589780462084172,\n",
       " 0.042038155498034704,\n",
       " 0.011695906432748537,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KS_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5760233918128654"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(KS_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(A_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycutoff=cutoffs[A_all==max(A_all)][0]\n",
    "mycutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.08152158])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Age', -0.038909996897488294),\n",
       " ('Fare', 0.002057291951272069),\n",
       " ('Parch', -0.09560241337591975),\n",
       " ('PassengerId', 0.00010246799898525618),\n",
       " ('Pclass', -1.080141182190641),\n",
       " ('SibSp', -0.31952026938881695),\n",
       " ('Embarked_S', -0.34529275972068685),\n",
       " ('Embarked_C', 0.07937338388121207),\n",
       " ('Sex_male', -2.706055861001125)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(x_train.columns,logr.coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'mysubmission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-0dd291cb09d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mysubmission.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3227\u001b[0m         )\n\u001b[1;32m-> 3228\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             )\n\u001b[0;32m    185\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'mysubmission.csv'"
     ]
    }
   ],
   "source": [
    "test_score=logr.predict_proba(t_test)[:,1]\n",
    "pd.DataFrame(test_score).to_csv(\"mysubmission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10911195, 0.36665827, 0.11049449, 0.10421071, 0.58461628,\n",
       "       0.16190819, 0.68600544, 0.1970062 , 0.79037466, 0.07416568,\n",
       "       0.09473253, 0.33318608, 0.93723375, 0.05981972, 0.84896269,\n",
       "       0.86957664, 0.26342972, 0.18321927, 0.55854646, 0.56899056,\n",
       "       0.295417  , 0.1742262 , 0.93458388, 0.66418911, 0.90381829,\n",
       "       0.03384684, 0.96612796, 0.17479365, 0.38030352, 0.08008121,\n",
       "       0.09559434, 0.17601151, 0.45960312, 0.49312893, 0.52537112,\n",
       "       0.19852178, 0.61108237, 0.68819826, 0.11223014, 0.10393781,\n",
       "       0.09316618, 0.48616927, 0.0633458 , 0.82218166, 0.85688398,\n",
       "       0.11197901, 0.44545904, 0.12916196, 0.88073703, 0.50824273,\n",
       "       0.47917055, 0.34786027, 0.76979448, 0.88642591, 0.324745  ,\n",
       "       0.07793177, 0.07880344, 0.11204504, 0.07209823, 0.96501496,\n",
       "       0.14705015, 0.22273409, 0.14222494, 0.75004037, 0.66292669,\n",
       "       0.82658553, 0.77818011, 0.33331224, 0.58068044, 0.7788707 ,\n",
       "       0.73531846, 0.12870699, 0.6183377 , 0.60388385, 0.96278095,\n",
       "       0.65573089, 0.09534145, 0.73675324, 0.2366254 , 0.73549791,\n",
       "       0.21362643, 0.19458441, 0.30932761, 0.09537596, 0.3061097 ,\n",
       "       0.10613437, 0.71237597, 0.71347114, 0.69037395, 0.38338308,\n",
       "       0.61051678, 0.09542525, 0.90909217, 0.0954918 , 0.63563561,\n",
       "       0.11246296, 0.65540046, 0.09788086, 0.6974548 , 0.08500772,\n",
       "       0.90919223, 0.20669569, 0.12979718, 0.10871258, 0.73152395,\n",
       "       0.1042164 , 0.17311421, 0.12985506, 0.09574257, 0.32725447,\n",
       "       0.23737476, 0.69089033, 0.94521755, 0.77542949, 0.80916365,\n",
       "       0.15808278, 0.13887739, 0.76486141, 0.55779671, 0.78332023,\n",
       "       0.90422932, 0.09793995, 0.9322701 , 0.10148703, 0.13005202,\n",
       "       0.70600619, 0.12499894, 0.54951514, 0.16341063, 0.11681848,\n",
       "       0.08833896, 0.37190001, 0.52874894, 0.10504132, 0.05941226,\n",
       "       0.11684035, 0.15492316, 0.26706108, 0.67326259, 0.03054143,\n",
       "       0.38228356, 0.94211613, 0.27699724, 0.25730079, 0.37205518,\n",
       "       0.03798895, 0.50187431, 0.12529179, 0.48890858, 0.17474377,\n",
       "       0.96669173, 0.13966695, 0.03257555, 0.50899509, 0.04681472,\n",
       "       0.11698733, 0.95653448, 0.67360216, 0.37239039, 0.60562855,\n",
       "       0.69194144, 0.20852931, 0.84554273, 0.09592563, 0.16931802,\n",
       "       0.55543201, 0.43028556, 0.07164819, 0.95651195, 0.6828591 ,\n",
       "       0.09608609, 0.15285697, 0.09219879, 0.13977307, 0.03259751,\n",
       "       0.87981288, 0.87897803, 0.30526205, 0.74616352, 0.84292218,\n",
       "       0.23851853, 0.4503973 , 0.94560127, 0.13073754, 0.96211356,\n",
       "       0.17606556, 0.86019346, 0.08442901, 0.10401354, 0.17523124,\n",
       "       0.16683734, 0.48972686, 0.12653687, 0.11693908, 0.38830279,\n",
       "       0.0857444 , 0.79219774, 0.7156547 , 0.29074931, 0.61507485,\n",
       "       0.69620447, 0.21879999, 0.45179845, 0.88238749, 0.27508927,\n",
       "       0.59495098, 0.64741642, 0.28297839, 0.95103609, 0.11365494,\n",
       "       0.09144562, 0.09636199, 0.37115998, 0.52212133, 0.21036354,\n",
       "       0.3814682 , 0.69322708, 0.22615609, 0.90627586, 0.0966128 ,\n",
       "       0.83973362, 0.13047648, 0.86479232, 0.1304404 , 0.89928835,\n",
       "       0.67249599, 0.12189747, 0.69341023, 0.06659087, 0.19952626,\n",
       "       0.39504455, 0.95296429, 0.09811533, 0.13135122, 0.45009603,\n",
       "       0.13507522, 0.2378203 , 0.19259528, 0.83243412, 0.90277033,\n",
       "       0.89223028, 0.69245179, 0.40167996, 0.09679842, 0.06227357,\n",
       "       0.32265525, 0.86758106, 0.11963629, 0.78555537, 0.64382645,\n",
       "       0.90056628, 0.13528392, 0.59946246, 0.11840932, 0.08803615,\n",
       "       0.09684523, 0.13158998, 0.1028978 , 0.87881323, 0.13085451,\n",
       "       0.05753281, 0.13089636, 0.80563885, 0.76587929, 0.32561501,\n",
       "       0.09699718, 0.47828795, 0.09695283, 0.61671704, 0.14995757,\n",
       "       0.46473366, 0.13176572, 0.95891822, 0.62650413, 0.14102103,\n",
       "       0.83906613, 0.25382689, 0.13791042, 0.18941146, 0.30057995,\n",
       "       0.67673102, 0.18152914, 0.69460703, 0.78699793, 0.76223063,\n",
       "       0.07759437, 0.09706931, 0.49668204, 0.14119594, 0.09724064,\n",
       "       0.49925629, 0.69196372, 0.14124565, 0.22487324, 0.07799261,\n",
       "       0.11065805, 0.93451766, 0.08212772, 0.49956889, 0.09971074,\n",
       "       0.08970574, 0.33007676, 0.15016701, 0.11880243, 0.69508502,\n",
       "       0.71666945, 0.42715849, 0.23217802, 0.21588288, 0.39590053,\n",
       "       0.14558677, 0.18190834, 0.09736182, 0.63200922, 0.91240161,\n",
       "       0.78905134, 0.32355659, 0.32653168, 0.10710342, 0.19212263,\n",
       "       0.1108859 , 0.16531963, 0.27078798, 0.46135761, 0.93690745,\n",
       "       0.12282208, 0.82912292, 0.46821394, 0.19789245, 0.3110187 ,\n",
       "       0.6721407 , 0.51090527, 0.14174249, 0.71584979, 0.10726851,\n",
       "       0.49048857, 0.22746977, 0.08679008, 0.28658687, 0.14183082,\n",
       "       0.33567073, 0.09001639, 0.03639483, 0.94828613, 0.06757916,\n",
       "       0.73414129, 0.27127386, 0.64192338, 0.28718085, 0.82347962,\n",
       "       0.9235659 , 0.27810318, 0.365445  , 0.09227839, 0.75923123,\n",
       "       0.30699604, 0.72214872, 0.09782302, 0.13278895, 0.5421903 ,\n",
       "       0.01405756, 0.86485   , 0.82367317, 0.1077049 , 0.9539658 ,\n",
       "       0.36173484, 0.10889796, 0.70065971, 0.92312006, 0.33712996,\n",
       "       0.24716943, 0.96375958, 0.30427162, 0.15633129, 0.80813793,\n",
       "       0.95254759, 0.53705581, 0.31141152, 0.27747542, 0.06420734,\n",
       "       0.13304876, 0.15059191, 0.62259743, 0.64583112, 0.24444446,\n",
       "       0.80154155, 0.11950343, 0.10063599, 0.17726845, 0.08921523,\n",
       "       0.5935891 , 0.85675544, 0.15006947, 0.14116998, 0.03857849,\n",
       "       0.94742471, 0.16085184, 0.89021802, 0.12807456, 0.12753053,\n",
       "       0.95075063, 0.14773023, 0.96719846, 0.62671656, 0.39457441,\n",
       "       0.42013408, 0.23326706, 0.39706691, 0.69732623, 0.75502647,\n",
       "       0.69738216, 0.92829987, 0.6355124 , 0.09836176, 0.94888095,\n",
       "       0.07179456, 0.09838903, 0.10191079])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score=(test_score>mycutoff).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0  1\n",
      "0     892  0\n",
      "1     893  0\n",
      "2     894  0\n",
      "3     895  0\n",
      "4     896  0\n",
      "..    ... ..\n",
      "413  1305  0\n",
      "414  1306  1\n",
      "415  1307  0\n",
      "416  1308  0\n",
      "417  1309  0\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "t_list=list(zip(t_test['PassengerId'],test_score))\n",
    "type(t_list)\n",
    "test_classes=pd.DataFrame(t_list)\n",
    "print(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_classes).to_csv(\"mysubmission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
